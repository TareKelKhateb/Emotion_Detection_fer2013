{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17RpC5vi2NDo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/fer2013.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparing data**"
      ],
      "metadata": {
        "id": "VqtIcn1a3ZKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "for index, row in df.iterrows():\n",
        "    k = row['pixels'].split(\" \")\n",
        "    if row['Usage'] == 'Training':\n",
        "        X_train.append(np.array(k))\n",
        "        y_train.append(row['emotion'])\n",
        "    elif row['Usage'] == 'PublicTest':\n",
        "        X_test.append(np.array(k))\n",
        "        y_test.append(row['emotion'])"
      ],
      "metadata": {
        "id": "VnOKPCb23PZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train, dtype = 'uint8')\n",
        "y_train = np.array(y_train, dtype = 'uint8')\n",
        "X_test = np.array(X_test, dtype = 'uint8')\n",
        "y_test = np.array(y_test, dtype = 'uint8')"
      ],
      "metadata": {
        "id": "yBUdbFfS3V0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*converting into categories*"
      ],
      "metadata": {
        "id": "H2M6jAD83riR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "y_train= to_categorical(y_train, num_classes=7)\n",
        "y_test = to_categorical(y_test, num_classes=7)"
      ],
      "metadata": {
        "id": "7sDr_2ch3nRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*reshaping the images*"
      ],
      "metadata": {
        "id": "hjRusw_u32LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ],
      "metadata": {
        "id": "dVgI9ZyO3xzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Image Augmentation*"
      ],
      "metadata": {
        "id": "uNxjA5Fd4BtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range = 10,\n",
        "    horizontal_flip = True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode = 'nearest')\n",
        "\n",
        "testgen = ImageDataGenerator(rescale=1./255)\n",
        "datagen.fit(X_train)\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "3INjKLOR31jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "baUrX7s-4IZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bulding the model**"
      ],
      "metadata": {
        "id": "Dhh7wxVv4bLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "#from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "fzsTwckq4Vxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FER_Model(input_shape=(48,48,1)):\n",
        "    # first input model\n",
        "    visible = Input(shape=input_shape, name='input')\n",
        "    num_classes = 7\n",
        "    #the 1-st block\n",
        "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
        "    conv1_1 = BatchNormalization()(conv1_1)\n",
        "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
        "    conv1_2 = BatchNormalization()(conv1_2)\n",
        "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
        "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
        "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
        "    conv2_1 = BatchNormalization()(conv2_1)\n",
        "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
        "    conv2_2 = BatchNormalization()(conv2_2)\n",
        "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
        "    conv2_2 = BatchNormalization()(conv2_3)\n",
        "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
        "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
        "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
        "    conv3_1 = BatchNormalization()(conv3_1)\n",
        "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
        "    conv3_2 = BatchNormalization()(conv3_2)\n",
        "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
        "    conv3_3 = BatchNormalization()(conv3_3)\n",
        "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
        "    conv3_4 = BatchNormalization()(conv3_4)\n",
        "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
        "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
        "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
        "    conv4_1 = BatchNormalization()(conv4_1)\n",
        "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
        "    conv4_2 = BatchNormalization()(conv4_2)\n",
        "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
        "    conv4_3 = BatchNormalization()(conv4_3)\n",
        "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
        "    conv4_4 = BatchNormalization()(conv4_4)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
        "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
        "\n",
        "    #the 5-th block\n",
        "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
        "    conv5_1 = BatchNormalization()(conv5_1)\n",
        "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
        "    conv5_2 = BatchNormalization()(conv5_2)\n",
        "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
        "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
        "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
        "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model\n",
        "    model = Model(inputs =visible, outputs = ouput)\n",
        "    # summary layers\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "gKvdsB_C4f-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FER_Model()\n",
        "opt = Adam(lr=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CRQxEIP4r1E",
        "outputId": "63bc8a1e-346c-4b90-f1ce-74f39d78c028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
            "                                                                 \n",
            " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 48, 48, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 48, 48, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 24, 24, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 24, 24, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,111,367\n",
            "Trainable params: 13,103,431\n",
            "Non-trainable params: 7,936\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "history = model.fit(train_flow,\n",
        "                    steps_per_epoch=len(X_train) / batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_flow,\n",
        "                    validation_steps=len(X_test) / batch_size,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Y_Iudv4yFy",
        "outputId": "781f4c0f-1a3c-4a7b-ffe7-75b2a5464651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.6663 - accuracy: 0.3363 - val_loss: 1.5960 - val_accuracy: 0.3702\n",
            "Epoch 2/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.5880 - accuracy: 0.3749 - val_loss: 1.5313 - val_accuracy: 0.4008\n",
            "Epoch 3/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.5247 - accuracy: 0.4085 - val_loss: 1.4617 - val_accuracy: 0.4300\n",
            "Epoch 4/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.4574 - accuracy: 0.4400 - val_loss: 1.3500 - val_accuracy: 0.4720\n",
            "Epoch 5/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.3990 - accuracy: 0.4616 - val_loss: 1.3023 - val_accuracy: 0.5216\n",
            "Epoch 6/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.3402 - accuracy: 0.4836 - val_loss: 1.2271 - val_accuracy: 0.5369\n",
            "Epoch 7/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.2925 - accuracy: 0.5041 - val_loss: 1.2138 - val_accuracy: 0.5547\n",
            "Epoch 8/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.2469 - accuracy: 0.5235 - val_loss: 1.1662 - val_accuracy: 0.5763\n",
            "Epoch 9/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.2093 - accuracy: 0.5410 - val_loss: 1.2525 - val_accuracy: 0.5458\n",
            "Epoch 10/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.1802 - accuracy: 0.5539 - val_loss: 1.1178 - val_accuracy: 0.5891\n",
            "Epoch 11/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.1552 - accuracy: 0.5618 - val_loss: 1.1165 - val_accuracy: 0.5903\n",
            "Epoch 12/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.1272 - accuracy: 0.5710 - val_loss: 1.1224 - val_accuracy: 0.5840\n",
            "Epoch 13/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.1031 - accuracy: 0.5834 - val_loss: 1.1047 - val_accuracy: 0.5941\n",
            "Epoch 14/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.0838 - accuracy: 0.5912 - val_loss: 1.0967 - val_accuracy: 0.6043\n",
            "Epoch 15/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.0696 - accuracy: 0.5994 - val_loss: 1.0616 - val_accuracy: 0.6158\n",
            "Epoch 16/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.0394 - accuracy: 0.6094 - val_loss: 1.0727 - val_accuracy: 0.6170\n",
            "Epoch 17/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.0339 - accuracy: 0.6095 - val_loss: 0.9949 - val_accuracy: 0.6349\n",
            "Epoch 18/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 1.0183 - accuracy: 0.6171 - val_loss: 1.0236 - val_accuracy: 0.6285\n",
            "Epoch 19/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.9992 - accuracy: 0.6244 - val_loss: 1.0229 - val_accuracy: 0.6272\n",
            "Epoch 20/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.9788 - accuracy: 0.6315 - val_loss: 1.0628 - val_accuracy: 0.5891\n",
            "Epoch 21/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.9683 - accuracy: 0.6360 - val_loss: 1.0596 - val_accuracy: 0.6132\n",
            "Epoch 22/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.9509 - accuracy: 0.6415 - val_loss: 1.0383 - val_accuracy: 0.6310\n",
            "Epoch 23/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.9393 - accuracy: 0.6488 - val_loss: 0.9744 - val_accuracy: 0.6323\n",
            "Epoch 24/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.9242 - accuracy: 0.6547 - val_loss: 0.9776 - val_accuracy: 0.6489\n",
            "Epoch 25/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.9067 - accuracy: 0.6602 - val_loss: 1.0147 - val_accuracy: 0.6336\n",
            "Epoch 26/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8981 - accuracy: 0.6621 - val_loss: 0.9909 - val_accuracy: 0.6628\n",
            "Epoch 27/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8877 - accuracy: 0.6667 - val_loss: 0.9825 - val_accuracy: 0.6196\n",
            "Epoch 28/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8765 - accuracy: 0.6713 - val_loss: 0.9679 - val_accuracy: 0.6552\n",
            "Epoch 29/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8632 - accuracy: 0.6740 - val_loss: 0.9647 - val_accuracy: 0.6603\n",
            "Epoch 30/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8484 - accuracy: 0.6832 - val_loss: 0.9444 - val_accuracy: 0.6590\n",
            "Epoch 31/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8375 - accuracy: 0.6845 - val_loss: 0.9298 - val_accuracy: 0.6692\n",
            "Epoch 32/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8284 - accuracy: 0.6881 - val_loss: 0.9917 - val_accuracy: 0.6450\n",
            "Epoch 33/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8186 - accuracy: 0.6929 - val_loss: 0.9692 - val_accuracy: 0.6489\n",
            "Epoch 34/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.8053 - accuracy: 0.6977 - val_loss: 0.8980 - val_accuracy: 0.6794\n",
            "Epoch 35/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7938 - accuracy: 0.7040 - val_loss: 0.9416 - val_accuracy: 0.6514\n",
            "Epoch 36/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7766 - accuracy: 0.7086 - val_loss: 0.9667 - val_accuracy: 0.6590\n",
            "Epoch 37/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7668 - accuracy: 0.7144 - val_loss: 0.9784 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7578 - accuracy: 0.7178 - val_loss: 0.9686 - val_accuracy: 0.6590\n",
            "Epoch 39/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7454 - accuracy: 0.7206 - val_loss: 1.0088 - val_accuracy: 0.6285\n",
            "Epoch 40/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7448 - accuracy: 0.7204 - val_loss: 0.9532 - val_accuracy: 0.6858\n",
            "Epoch 41/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7335 - accuracy: 0.7261 - val_loss: 0.9019 - val_accuracy: 0.6756\n",
            "Epoch 42/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7187 - accuracy: 0.7317 - val_loss: 0.9424 - val_accuracy: 0.6743\n",
            "Epoch 43/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.7094 - accuracy: 0.7360 - val_loss: 0.9642 - val_accuracy: 0.6628\n",
            "Epoch 44/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6920 - accuracy: 0.7421 - val_loss: 0.9294 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6816 - accuracy: 0.7444 - val_loss: 0.9028 - val_accuracy: 0.6692\n",
            "Epoch 46/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6764 - accuracy: 0.7489 - val_loss: 0.9433 - val_accuracy: 0.6870\n",
            "Epoch 47/100\n",
            "448/448 [==============================] - 38s 84ms/step - loss: 0.6659 - accuracy: 0.7535 - val_loss: 0.9166 - val_accuracy: 0.6832\n",
            "Epoch 48/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6571 - accuracy: 0.7537 - val_loss: 0.9442 - val_accuracy: 0.6756\n",
            "Epoch 49/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6428 - accuracy: 0.7616 - val_loss: 1.0196 - val_accuracy: 0.6705\n",
            "Epoch 50/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6372 - accuracy: 0.7626 - val_loss: 0.9509 - val_accuracy: 0.6794\n",
            "Epoch 51/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6220 - accuracy: 0.7687 - val_loss: 1.0038 - val_accuracy: 0.6628\n",
            "Epoch 52/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6160 - accuracy: 0.7709 - val_loss: 0.9700 - val_accuracy: 0.6756\n",
            "Epoch 53/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.6018 - accuracy: 0.7739 - val_loss: 1.0124 - val_accuracy: 0.6756\n",
            "Epoch 54/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5944 - accuracy: 0.7771 - val_loss: 0.9620 - val_accuracy: 0.6908\n",
            "Epoch 55/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5921 - accuracy: 0.7794 - val_loss: 0.9788 - val_accuracy: 0.6896\n",
            "Epoch 56/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5801 - accuracy: 0.7839 - val_loss: 1.0011 - val_accuracy: 0.6641\n",
            "Epoch 57/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5706 - accuracy: 0.7877 - val_loss: 1.0166 - val_accuracy: 0.6947\n",
            "Epoch 58/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5592 - accuracy: 0.7942 - val_loss: 1.0391 - val_accuracy: 0.6590\n",
            "Epoch 59/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5482 - accuracy: 0.7993 - val_loss: 1.0491 - val_accuracy: 0.6730\n",
            "Epoch 60/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5434 - accuracy: 0.7963 - val_loss: 1.0741 - val_accuracy: 0.6578\n",
            "Epoch 61/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5382 - accuracy: 0.7991 - val_loss: 1.0518 - val_accuracy: 0.6883\n",
            "Epoch 62/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5263 - accuracy: 0.8029 - val_loss: 1.0839 - val_accuracy: 0.6832\n",
            "Epoch 63/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5167 - accuracy: 0.8041 - val_loss: 1.0722 - val_accuracy: 0.6781\n",
            "Epoch 64/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.5130 - accuracy: 0.8109 - val_loss: 1.0374 - val_accuracy: 0.6756\n",
            "Epoch 65/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4974 - accuracy: 0.8155 - val_loss: 1.0222 - val_accuracy: 0.6807\n",
            "Epoch 66/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4869 - accuracy: 0.8206 - val_loss: 1.1094 - val_accuracy: 0.6781\n",
            "Epoch 67/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4851 - accuracy: 0.8206 - val_loss: 1.0827 - val_accuracy: 0.6730\n",
            "Epoch 68/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4794 - accuracy: 0.8228 - val_loss: 1.1232 - val_accuracy: 0.6845\n",
            "Epoch 69/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4683 - accuracy: 0.8247 - val_loss: 1.1237 - val_accuracy: 0.6705\n",
            "Epoch 70/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4610 - accuracy: 0.8296 - val_loss: 1.1061 - val_accuracy: 0.6807\n",
            "Epoch 71/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4641 - accuracy: 0.8279 - val_loss: 1.1404 - val_accuracy: 0.6832\n",
            "Epoch 72/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4487 - accuracy: 0.8331 - val_loss: 1.1469 - val_accuracy: 0.6654\n",
            "Epoch 73/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4430 - accuracy: 0.8362 - val_loss: 1.1754 - val_accuracy: 0.6641\n",
            "Epoch 74/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4358 - accuracy: 0.8384 - val_loss: 1.1353 - val_accuracy: 0.6832\n",
            "Epoch 75/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4243 - accuracy: 0.8422 - val_loss: 1.1473 - val_accuracy: 0.6858\n",
            "Epoch 76/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4252 - accuracy: 0.8433 - val_loss: 1.1318 - val_accuracy: 0.6756\n",
            "Epoch 77/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4165 - accuracy: 0.8465 - val_loss: 1.1493 - val_accuracy: 0.6768\n",
            "Epoch 78/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4114 - accuracy: 0.8471 - val_loss: 1.1617 - val_accuracy: 0.6756\n",
            "Epoch 79/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.4001 - accuracy: 0.8508 - val_loss: 1.2416 - val_accuracy: 0.6730\n",
            "Epoch 80/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3953 - accuracy: 0.8550 - val_loss: 1.2030 - val_accuracy: 0.7010\n",
            "Epoch 81/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3850 - accuracy: 0.8577 - val_loss: 1.2211 - val_accuracy: 0.6628\n",
            "Epoch 82/100\n",
            "448/448 [==============================] - 38s 84ms/step - loss: 0.3795 - accuracy: 0.8588 - val_loss: 1.2551 - val_accuracy: 0.6756\n",
            "Epoch 83/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3811 - accuracy: 0.8575 - val_loss: 1.1386 - val_accuracy: 0.6845\n",
            "Epoch 84/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3738 - accuracy: 0.8633 - val_loss: 1.1816 - val_accuracy: 0.6972\n",
            "Epoch 85/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3622 - accuracy: 0.8643 - val_loss: 1.1800 - val_accuracy: 0.6883\n",
            "Epoch 86/100\n",
            "448/448 [==============================] - 38s 84ms/step - loss: 0.3588 - accuracy: 0.8673 - val_loss: 1.1890 - val_accuracy: 0.6718\n",
            "Epoch 87/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3511 - accuracy: 0.8701 - val_loss: 1.3057 - val_accuracy: 0.6807\n",
            "Epoch 88/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3487 - accuracy: 0.8713 - val_loss: 1.2134 - val_accuracy: 0.6667\n",
            "Epoch 89/100\n",
            "448/448 [==============================] - 38s 84ms/step - loss: 0.3490 - accuracy: 0.8709 - val_loss: 1.2312 - val_accuracy: 0.6794\n",
            "Epoch 90/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3402 - accuracy: 0.8753 - val_loss: 1.2299 - val_accuracy: 0.6705\n",
            "Epoch 91/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3326 - accuracy: 0.8776 - val_loss: 1.2630 - val_accuracy: 0.6870\n",
            "Epoch 92/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3240 - accuracy: 0.8808 - val_loss: 1.2019 - val_accuracy: 0.6883\n",
            "Epoch 93/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3221 - accuracy: 0.8802 - val_loss: 1.2844 - val_accuracy: 0.6896\n",
            "Epoch 94/100\n",
            "448/448 [==============================] - 38s 84ms/step - loss: 0.3182 - accuracy: 0.8837 - val_loss: 1.3093 - val_accuracy: 0.6934\n",
            "Epoch 95/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3214 - accuracy: 0.8810 - val_loss: 1.3423 - val_accuracy: 0.6768\n",
            "Epoch 96/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3070 - accuracy: 0.8885 - val_loss: 1.4075 - val_accuracy: 0.6730\n",
            "Epoch 97/100\n",
            "448/448 [==============================] - 38s 84ms/step - loss: 0.3036 - accuracy: 0.8895 - val_loss: 1.4132 - val_accuracy: 0.6730\n",
            "Epoch 98/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.3014 - accuracy: 0.8875 - val_loss: 1.3472 - val_accuracy: 0.6768\n",
            "Epoch 99/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.2930 - accuracy: 0.8924 - val_loss: 1.3553 - val_accuracy: 0.6908\n",
            "Epoch 100/100\n",
            "448/448 [==============================] - 38s 85ms/step - loss: 0.2952 - accuracy: 0.8892 - val_loss: 1.4040 - val_accuracy: 0.6730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaNGrzEQ5C1H",
        "outputId": "94a0afcc-a53f-4e62-ccaf-e69c0d2cf836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    }
  ]
}